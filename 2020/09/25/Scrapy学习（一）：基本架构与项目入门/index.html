<!DOCTYPE html>



  


<html class="theme-next gemini use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">

<script>
    (function(){
        if(''){
            if (prompt('请输入密码') !== ''){
                alert('密码错误');
                history.back();
            }
        }
    })();
</script>


  
  
    
    
  <script src="/lib/pace/pace.min.js?v=1.0.2"></script>
  <link href="/lib/pace/pace-theme-center-atom.min.css?v=1.0.2" rel="stylesheet">







<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  
    
      
    

    
  

  

  
    
      
    

    
  

  
    
      
    

    
  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Lobster Two:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16.png?v=5.1.4">






  <meta name="keywords" content="Scrapy," />










<meta name="description" content="概要Scrapy 是一个基于 Twisted 的异步处理框架，是纯 Python 实现的爬虫框架，其架构清晰，可扩展性极强。本文主要是通过一个简单的爬虫项目，完成一遍 Scrapy 抓取流程。">
<meta property="og:type" content="article">
<meta property="og:title" content="Scrapy学习（一）：基本架构与项目入门">
<meta property="og:url" content="https://xza0226.com/2020/09/25/Scrapy%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E4%B8%8E%E9%A1%B9%E7%9B%AE%E5%85%A5%E9%97%A8/index.html">
<meta property="og:site_name" content="paragon‘s blog">
<meta property="og:description" content="概要Scrapy 是一个基于 Twisted 的异步处理框架，是纯 Python 实现的爬虫框架，其架构清晰，可扩展性极强。本文主要是通过一个简单的爬虫项目，完成一遍 Scrapy 抓取流程。">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/007S8ZIlly1gj30d6gdh9j31400t2183.jpg">
<meta property="og:image" content="https://tva1.sinaimg.cn/large/007S8ZIlly1gj31kruen1j30zk0u07co.jpg">
<meta property="article:published_time" content="2020-09-24T16:00:00.000Z">
<meta property="article:modified_time" content="2020-09-26T16:00:00.000Z">
<meta property="article:author" content="paragon">
<meta property="article:tag" content="Scrapy">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://tva1.sinaimg.cn/large/007S8ZIlly1gj30d6gdh9j31400t2183.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":true,"scrollpercent":true,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://xza0226.com/2020/09/25/Scrapy学习（一）：基本架构与项目入门/"/>





  <title>Scrapy学习（一）：基本架构与项目入门 | paragon‘s blog</title>
  








<meta name="generator" content="Hexo 4.2.1"></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">paragon‘s blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">札记</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://xza0226.com/2020/09/25/Scrapy%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E4%B8%8E%E9%A1%B9%E7%9B%AE%E5%85%A5%E9%97%A8/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="paragon">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="paragon‘s blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Scrapy学习（一）：基本架构与项目入门</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-09-25T00:00:00+08:00">
                2020-09-25
              </time>
            

            
              <span class="post-meta-divider">|</span>
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-check-o"></i>
              </span>
              
                <span class="post-meta-item-text">更新于&#58;</span>
              
              <time title="更新于" itemprop="dateModified" datetime="2020-09-27T00:00:00+08:00">
                2020-09-27
              </time>
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E7%88%AC%E8%99%AB/" itemprop="url" rel="index">
                    <span itemprop="name">爬虫</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2020/09/25/Scrapy%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E4%B8%8E%E9%A1%B9%E7%9B%AE%E5%85%A5%E9%97%A8/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count valine-comment-count" data-xid="/2020/09/25/Scrapy%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E5%9F%BA%E6%9C%AC%E6%9E%B6%E6%9E%84%E4%B8%8E%E9%A1%B9%E7%9B%AE%E5%85%A5%E9%97%A8/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv">本文总阅读量 <i class="fa fa-file-o"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>次
            </span>
          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">字数统计&#58;</span>
                
                <span title="字数统计">
                  4.2k
                </span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">
                  17
                </span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="概要"><a href="#概要" class="headerlink" title="概要"></a>概要</h2><p>Scrapy 是一个基于 Twisted 的异步处理框架，是纯 Python 实现的爬虫框架，其架构清晰，可扩展性极强。本文主要是通过一个简单的爬虫项目，完成一遍 Scrapy 抓取流程。</p>
<a id="more"></a>

<h2 id="Scrapy框架介绍"><a href="#Scrapy框架介绍" class="headerlink" title="Scrapy框架介绍"></a>Scrapy框架介绍</h2><h3 id="1-架构模式"><a href="#1-架构模式" class="headerlink" title="1.架构模式"></a>1.架构模式</h3><p>Scrapy 架构可以分为如下的几个部分：</p>
<ul>
<li><p>Engine，引擎，用来处理整个系统的数据流处理，触发事务，是整个框架的核心。</p>
</li>
<li><p>Item，项目，它定义了爬取结果的数据结构，爬取的数据会被赋值成该对象。</p>
</li>
<li><p>Scheduler， 调度器，用来接受引擎发过来的请求并加入队列中，并在引擎再次请求的时候提供给引擎。</p>
</li>
<li><p>Downloader，下载器，用于下载网页内容，并将网页内容返回给蜘蛛。</p>
</li>
<li><p>Spiders，蜘蛛，其内定义了爬取的逻辑和网页的解析规则，它主要负责解析响应并生成提取结果和新的请求。</p>
</li>
<li><p>Item Pipeline，项目管道，负责处理由蜘蛛从网页中抽取的项目，它的主要任务是清洗、验证和存储数据。</p>
</li>
<li><p>Downloader Middlewares，下载器中间件，位于引擎和下载器之间的钩子框架，主要是处理引擎与下载器之间的请求及响应。</p>
</li>
<li><p>Spider Middlewares， 蜘蛛中间件，位于引擎和蜘蛛之间的钩子框架，主要工作是处理蜘蛛输入的响应和输出的结果及新的请求。</p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gj30d6gdh9j31400t2183.jpg" alt=""></p>
</li>
</ul>
<h3 id="2-数据流"><a href="#2-数据流" class="headerlink" title="2.数据流"></a>2.数据流</h3><p>Scrapy 中的数据流由引擎控制，其过程如下:</p>
<ul>
<li>Engine 首先打开一个网站，找到处理该网站的 Spider 并向该 Spider 请求第一个要爬取的 URL。</li>
<li>Engine 从 Spider 中获取到第一个要爬取的 URL 并通过 Scheduler 以 Request 的形式调度。</li>
<li>Engine 向 Scheduler 请求下一个要爬取的 URL。</li>
<li>Scheduler 返回下一个要爬取的 URL 给 Engine，Engine 将 URL 通过 Downloader Middlewares 转发给 Downloader 下载。</li>
<li>一旦页面下载完毕， Downloader 生成一个该页面的 Response，并将其通过 Downloader Middlewares 发送给 Engine。</li>
<li>Engine 从下载器中接收到 Response 并通过 Spider Middlewares 发送给 Spider 处理。</li>
<li>Spider 处理 Response 并返回爬取到的 Item 及新的 Request 给 Engine。</li>
<li>Engine 将 Spider 返回的 Item 给 Item Pipeline，将新的 Request 给 Scheduler。</li>
<li>重复第二步到最后一步，直到 Scheduler 中没有更多的 Request，Engine 关闭该网站，爬取结束。</li>
</ul>
<p>通过多个组件的相互协作、不同组件完成工作的不同、组件对异步处理的支持，Scrapy 最大限度地利用了网络带宽，大大提高了数据爬取和处理的效率。</p>
<h3 id="3-项目结构"><a href="#3-项目结构" class="headerlink" title="3.项目结构"></a>3.项目结构</h3><p>Scrapy 框架和 pyspider 不同，它是通过命令行来创建项目的，代码的编写还是需要 IDE。项目创建之后，项目文件结构如下所示：</p>
<blockquote>
<figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">scrapy.cfg</span><br><span class="line">project/</span><br><span class="line">    __init__.py</span><br><span class="line">    items.py</span><br><span class="line">    pipelines.py</span><br><span class="line">    settings.py</span><br><span class="line">    middlewares.py</span><br><span class="line">    spiders/</span><br><span class="line">        __init__.py</span><br><span class="line">        spider1.py</span><br><span class="line">        spider2.py</span><br><span class="line">        ...</span><br></pre></td></tr></table></figure>
</blockquote>
<p>各个文件的功能描述如下：</p>
<ul>
<li>scrapy.cfg：它是 Scrapy 项目的配置文件，其内定义了项目的配置文件路径、部署相关信息等内容。</li>
<li>items.py：它定义 Item 数据结构，所有的 Item 的定义都可以放这里。</li>
<li>pipelines.py：它定义 Item Pipeline 的实现，所有的 Item Pipeline 的实现都可以放这里。</li>
<li>settings.py：它定义项目的全局配置。</li>
<li>middlewares.py：它定义 Spider Middlewares 和 Downloader Middlewares 的实现。</li>
<li>spiders：其内包含一个个 Spider 的实现，每个 Spider 都有一个文件。</li>
</ul>
<h2 id="Scrapy入门"><a href="#Scrapy入门" class="headerlink" title="Scrapy入门"></a>Scrapy入门</h2><h3 id="1-项目创建"><a href="#1-项目创建" class="headerlink" title="1.项目创建"></a>1.项目创建</h3><blockquote>
<figure class="highlight 1c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy startproject projects <span class="comment">//创建项目</span></span><br></pre></td></tr></table></figure>
</blockquote>
<p>这个命令将会创建一个名为 projects 的文件夹，文件夹结构如下所示：</p>
<blockquote>
<figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">scrapy.cfg     <span class="comment"># Scrapy 部署时的配置文件</span></span><br><span class="line">projects       <span class="comment"># 项目的模块，引入的时候需要从这里引入</span></span><br><span class="line">    __init__.py    </span><br><span class="line">    <span class="keyword">items</span>.py     <span class="comment"># Items 的定义，定义爬取的数据结构</span></span><br><span class="line">    middlewares.py   <span class="comment"># Middlewares 的定义，定义爬取时的中间件</span></span><br><span class="line">    pipelines.py       <span class="comment"># Pipelines 的定义，定义数据管道</span></span><br><span class="line">    settings.py       <span class="comment"># 配置文件</span></span><br><span class="line">    spiders         <span class="comment"># 放置 Spiders 的文件夹</span></span><br><span class="line">    __init__.py</span><br></pre></td></tr></table></figure>
</blockquote>
<h3 id="2-创建Spiders"><a href="#2-创建Spiders" class="headerlink" title="2.创建Spiders"></a>2.创建Spiders</h3><p>Spider 是自己定义的类，Scrapy 用它来从网页里抓取内容，并解析抓取的结果。不过这个类必须继承 Scrapy 提供的 Spider 类 scrapy.Spider，还要定义 Spider 的名称和起始请求，以及怎样处理爬取后的结果的方法。</p>
<p>也可以使用命令行创建一个 Spider。比如要生成 Quotes 这个 Spider，可以执行如下命令：</p>
<blockquote>
<figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd projects</span><br><span class="line">scrapy genspider quotes <span class="string">http:</span><span class="comment">//quotes.toscrape.com/ </span></span><br></pre></td></tr></table></figure>
</blockquote>
<p>进入刚才创建的 projects 文件夹，然后执行 genspider 命令。第一个参数是 Spider 的名称，第二个参数是网站域名。执行完毕之后，spiders 文件夹中多了一个 quotes.py，它就是刚刚创建的 Spider，内容如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'quotes'</span></span><br><span class="line">    allowed_domains = [<span class="string">'quotes.toscrape.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://quotes.toscrape.com/'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="keyword">pass</span></span><br></pre></td></tr></table></figure>

<p>这里有三个属性 ——name、allowed_domains 和 start_urls，还有一个方法 parse。</p>
<ul>
<li>name，它是每个项目唯一的名字，用来区分不同的 Spider。</li>
<li>allowed_domains，它是允许爬取的域名，如果初始或后续的请求链接不是这个域名下的，则请求链接会被过滤掉。</li>
<li>start_urls，它包含了 Spider 在启动时爬取的 url 列表，初始请求是由它来定义的。</li>
<li>parse，它是 Spider 的一个方法。默认情况下，被调用时 start_urls 里面的链接构成的请求完成下载执行后，返回的响应就会作为唯一的参数传递给这个函数。该方法负责解析返回的响应、提取数据或者进一步生成要处理的请求。</li>
</ul>
<h3 id="3-创建Item"><a href="#3-创建Item" class="headerlink" title="3.创建Item"></a>3.创建Item</h3><p>Item 是保存爬取数据的容器，它的使用方法和字典类似。不过，相比字典，Item 多了额外的保护机制，可以避免拼写错误或者定义字段错误。</p>
<p>创建 Item 需要继承 scrapy.Item 类，并且定义类型为 scrapy.Field 的字段。观察目标网站，我们可以获取到的内容有 text、author、tags。</p>
<p>定义 Item，此时将 items.py 修改如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuoteItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">  </span><br><span class="line">    text = scrapy.Field()</span><br><span class="line">    author = scrapy.Field()</span><br><span class="line">    tags = scrapy.Field()</span><br></pre></td></tr></table></figure>

<p>这里定义了三个字段，将类的名称修改为 QuoteItem，接下来爬取时我们会使用到这个 Item。</p>
<h3 id="4-解析Response"><a href="#4-解析Response" class="headerlink" title="4.解析Response"></a>4.解析Response</h3><p>前面我们看到，parse() 方法的参数 response 是 start_urls 里面的链接爬取后的结果。所以在 parse() 方法中，我们可以直接对 response 变量包含的内容进行解析，比如浏览请求结果的网页源代码，或者进一步分析源代码内容，或者找出结果中的链接而得到下一个请求。</p>
<p>我们可以看到网页中既有我们想要的结果，又有下一页的链接，这两部分内容我们都要进行处理。</p>
<p>首先看看网页结构，如图 13-2 所示。每一页都有多个 class 为 quote 的区块，每个区块内都包含 text、author、tags。那么我们先找出所有的 quote，然后提取每一个 quote 中的内容。</p>
<p><img src="https://tva1.sinaimg.cn/large/007S8ZIlly1gj31kruen1j30zk0u07co.jpg" alt=""></p>
<p>提取的方式可以是 CSS 选择器或 XPath 选择器。在这里我们使用 CSS 选择器进行选择，parse() 方法的改写如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">  quotes = response.css(<span class="string">'.quote'</span>)</span><br><span class="line">  <span class="keyword">for</span> quote <span class="keyword">in</span> quotes:</span><br><span class="line">    text = quote.css(<span class="string">'.text::text'</span>).extract_first()</span><br><span class="line">    author = quote.css(<span class="string">'.author::text'</span>).extract_first()</span><br><span class="line">    tags = quote.css(<span class="string">'.tags .tag::text'</span>).extract()</span><br></pre></td></tr></table></figure>

<p>这里首先利用选择器选取所有的 quote，并将其赋值为 quotes 变量，然后利用 for 循环对每个 quote 遍历，解析每个 quote 的内容。</p>
<p>对 text 来说，观察到它的 class 为 text，所以可以用.text 选择器来选取，这个结果实际上是整个带有标签的节点，要获取它的正文内容，可以加::text 来获取。这时的结果是长度为 1 的列表，所以还需要用 extract_first() 方法来获取第一个元素。而对于 tags 来说，由于我们要获取所有的标签，所以用 extract() 方法获取整个列表即可。</p>
<h3 id="5-使用Item"><a href="#5-使用Item" class="headerlink" title="5.使用Item"></a>5.使用Item</h3><p>上文定义了 Item，接下来就要使用它了。Item 可以理解为一个字典，不过在声明的时候需要实例化。然后依次用刚才解析的结果赋值 Item 的每一个字段，最后将 Item 返回即可。</p>
<p><strong>quotes.py</strong>的改写如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> projects.items <span class="keyword">import</span> QuoteItem</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'quotes'</span></span><br><span class="line">    allowed_domains = [<span class="string">'quotes.toscrape.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://quotes.toscrape.com/'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        quotes = response.css(<span class="string">'.quote'</span>)</span><br><span class="line">        <span class="keyword">for</span> quote <span class="keyword">in</span> quotes:</span><br><span class="line">            item = QuoteItem()</span><br><span class="line">            item[<span class="string">'text'</span>] = quote.css(<span class="string">'.text::text'</span>).extract_first()</span><br><span class="line">            item[<span class="string">'author'</span>] = quote.css(<span class="string">'.author::text'</span>).extract_first()</span><br><span class="line">            item[<span class="string">'tags'</span>] = quote.css(<span class="string">'.tags .tag::text'</span>).extract()</span><br><span class="line">            <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure>

<p>如此一来，首页的所有内容被解析出来，并被赋值成了一个个 QuoteItem。</p>
<h3 id="6-后续Request请求"><a href="#6-后续Request请求" class="headerlink" title="6.后续Request请求"></a>6.后续Request请求</h3><p>上面的操作实现了从初始页面抓取内容。那么，下一页的内容该如何抓取？这就需要我们从当前页面中找到信息来生成下一个请求，然后在下一个请求的页面里找到信息再构造再下一个请求。这样循环往复迭代，从而实现整站的爬取。</p>
<p>将刚才的页面拉到最底部，发现有一个 Next 按钮，查看一下源代码，可以发现它的链接是 /page/2/，实际上全链接就是：<a href="http://quotes.toscrape.com/page/2，通过这个链接我们就可以构造下一个请求。" target="_blank" rel="noopener">http://quotes.toscrape.com/page/2，通过这个链接我们就可以构造下一个请求。</a></p>
<p>构造请求时需要用到 scrapy.Request。这里我们传递两个参数 ——url 和 callback，这两个参数的说明如下。</p>
<ul>
<li>url：它是请求链接。</li>
<li>callback：它是回调函数。当指定了该回调函数的请求完成之后，获取到响应，引擎会将该响应作为参数传递给这个回调函数。回调函数进行解析或生成下一个请求，回调函数如上文的 parse() 所示。</li>
</ul>
<p>由于 parse() 就是解析 text、author、tags 的方法，而下一页的结构和刚才已经解析的页面结构是一样的，所以我们可以再次使用 parse() 方法来做页面解析。</p>
<p>接下来我们要做的就是利用选择器得到下一页链接并生成请求，在 parse() 方法后追加如下的代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">next = response.css(<span class="string">'.pager .next a::attr(href)'</span>).extract_first()</span><br><span class="line">url = response.urljoin(next)</span><br><span class="line"><span class="keyword">yield</span> scrapy.Request(url=url, callback=self.parse)</span><br></pre></td></tr></table></figure>

<p>第一句代码首先通过 CSS 选择器获取下一个页面的链接，即要获取 a 超链接中的 href 属性。这里用到了::attr(href) 操作。然后再调用 extract_first() 方法获取内容。</p>
<p>第二句代码调用了 urljoin() 方法，urljoin() 方法可以将相对 URL 构造成一个绝对的 URL。例如，获取到的下一页地址是 /page/2，urljoin() 方法处理后得到的结果就是：<a href="http://quotes.toscrape.com/page/2/。" target="_blank" rel="noopener">http://quotes.toscrape.com/page/2/。</a></p>
<p>第三句代码通过 url 和 callback 变量构造了一个新的请求，回调函数 callback 依然使用 parse() 方法。这个请求完成后，响应会重新经过 parse 方法处理，得到第二页的解析结果，然后生成第二页的下一页，也就是第三页的请求。这样爬虫就进入了一个循环，直到最后一页。</p>
<p>通过几行代码，我们就轻松实现了一个抓取循环，将每个页面的结果抓取下来了。</p>
<p>现在，改写之后的整个 Spider 类如下所示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> projects.items <span class="keyword">import</span> QuoteItem</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">QuotesSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'quotes'</span></span><br><span class="line">    allowed_domains = [<span class="string">'quotes.toscrape.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://quotes.toscrape.com/'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        quotes = response.css(<span class="string">'.quote'</span>)</span><br><span class="line">        <span class="keyword">for</span> quote <span class="keyword">in</span> quotes:</span><br><span class="line">            item = QuoteItem()</span><br><span class="line">            item[<span class="string">'text'</span>] = quote.css(<span class="string">'.text::text'</span>).extract_first()</span><br><span class="line">            item[<span class="string">'author'</span>] = quote.css(<span class="string">'.author::text'</span>).extract_first()</span><br><span class="line">            item[<span class="string">'tags'</span>] = quote.css(<span class="string">'.tags .tag::text'</span>).extract()</span><br><span class="line">            <span class="keyword">yield</span> item</span><br><span class="line">       </span><br><span class="line">        next = response.css(<span class="string">'.pager .next a::attr(href)'</span>).extract_first()</span><br><span class="line">        url = response.urljoin(next)</span><br><span class="line">        <span class="keyword">yield</span> scrapy.Request(url=url, callback=self.parse)</span><br></pre></td></tr></table></figure>

<h3 id="7-项目运行"><a href="#7-项目运行" class="headerlink" title="7.项目运行"></a>7.项目运行</h3><p>进入目录，运行如下命令：就可以看到 Scrapy 的运行结果了。</p>
<blockquote>
<figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">scrapy crawl quotes</span></span><br></pre></td></tr></table></figure>
</blockquote>
<p>具体结果展示如下：</p>
<figure class="highlight angelscript"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line">➜  projects scrapy crawl quotes   </span><br><span class="line"><span class="number">2020</span><span class="number">-09</span><span class="number">-25</span> <span class="number">18</span>:<span class="number">09</span>:<span class="number">17</span> [scrapy.utils.log] INFO: Scrapy <span class="number">1.8</span><span class="number">.0</span> started (bot: projects)</span><br><span class="line"><span class="number">2020</span><span class="number">-09</span><span class="number">-25</span> <span class="number">18</span>:<span class="number">09</span>:<span class="number">17</span> [scrapy.utils.log] INFO: Versions: lxml <span class="number">4.5</span><span class="number">.0</span><span class="number">.0</span>, libxml2 <span class="number">2.9</span><span class="number">.9</span>, cssselect <span class="number">1.1</span><span class="number">.0</span>, parsel <span class="number">1.6</span><span class="number">.0</span>, w3lib <span class="number">1.22</span><span class="number">.0</span>, Twisted <span class="number">20.3</span><span class="number">.0</span>, Python <span class="number">3.7</span><span class="number">.6</span> (<span class="keyword">default</span>, Jan  <span class="number">8</span> <span class="number">2020</span>, <span class="number">13</span>:<span class="number">42</span>:<span class="number">34</span>) - [Clang <span class="number">4.0</span><span class="number">.1</span> (tags/RELEASE_401/<span class="keyword">final</span>)], pyOpenSSL <span class="number">19.1</span><span class="number">.0</span> (OpenSSL <span class="number">1.1</span><span class="number">.1</span>d  <span class="number">10</span> Sep <span class="number">2019</span>), cryptography <span class="number">2.8</span>, Platform Darwin<span class="number">-19.6</span><span class="number">.0</span>-x86_64-i386<span class="number">-64</span>bit</span><br><span class="line"><span class="number">2020</span><span class="number">-09</span><span class="number">-25</span> <span class="number">18</span>:<span class="number">09</span>:<span class="number">17</span> [scrapy.crawler] INFO: Overridden settings: &#123;<span class="string">'BOT_NAME'</span>: <span class="string">'projects'</span>, <span class="string">'NEWSPIDER_MODULE'</span>: <span class="string">'projects.spiders'</span>, <span class="string">'ROBOTSTXT_OBEY'</span>: True, <span class="string">'SPIDER_MODULES'</span>: [<span class="string">'projects.spiders'</span>]&#125;</span><br><span class="line"><span class="number">2020</span><span class="number">-09</span><span class="number">-25</span> <span class="number">18</span>:<span class="number">09</span>:<span class="number">18</span> [scrapy.extensions.telnet] INFO: Telnet Password: <span class="number">4e7</span>bf07a3653a00e</span><br><span class="line"><span class="number">2020</span><span class="number">-09</span><span class="number">-25</span> <span class="number">18</span>:<span class="number">09</span>:<span class="number">18</span> [scrapy.middleware] INFO: Enabled extensions:</span><br><span class="line">[]</span><br><span class="line"><span class="number">2020</span><span class="number">-09</span><span class="number">-25</span> <span class="number">18</span>:<span class="number">09</span>:<span class="number">18</span> [scrapy.middleware] INFO: Enabled downloader middlewares:</span><br><span class="line">[]</span><br><span class="line"><span class="number">2020</span><span class="number">-09</span><span class="number">-25</span> <span class="number">18</span>:<span class="number">09</span>:<span class="number">18</span> [scrapy.middleware] INFO: Enabled spider middlewares:</span><br><span class="line">[]</span><br><span class="line"><span class="number">2020</span><span class="number">-09</span><span class="number">-25</span> <span class="number">18</span>:<span class="number">09</span>:<span class="number">18</span> [scrapy.middleware] INFO: Enabled item pipelines:</span><br><span class="line">[]</span><br><span class="line"><span class="number">2020</span><span class="number">-09</span><span class="number">-25</span> <span class="number">18</span>:<span class="number">09</span>:<span class="number">18</span> [scrapy.core.engine] INFO: Spider opened</span><br><span class="line"><span class="number">2020</span><span class="number">-09</span><span class="number">-25</span> <span class="number">18</span>:<span class="number">09</span>:<span class="number">18</span> [scrapy.extensions.logstats] INFO: Crawled <span class="number">0</span> pages (at <span class="number">0</span> pages/min), scraped <span class="number">0</span> items (at <span class="number">0</span> items/min)</span><br><span class="line"><span class="number">2020</span><span class="number">-09</span><span class="number">-25</span> <span class="number">18</span>:<span class="number">09</span>:<span class="number">18</span> [scrapy.extensions.telnet] INFO: Telnet console listening on <span class="number">127.0</span><span class="number">.0</span><span class="number">.1</span>:<span class="number">6023</span></span><br><span class="line"><span class="number">2020</span><span class="number">-09</span><span class="number">-25</span> <span class="number">18</span>:<span class="number">09</span>:<span class="number">19</span> [scrapy.core.engine] DEBUG: Crawled (<span class="number">404</span>) &lt;GET http:<span class="comment">//quotes.toscrape.com/robots.txt&gt; (referer: None)</span></span><br><span class="line"><span class="number">2020</span><span class="number">-09</span><span class="number">-25</span> <span class="number">18</span>:<span class="number">09</span>:<span class="number">20</span> [scrapy.core.engine] DEBUG: Crawled (<span class="number">200</span>) &lt;GET http:<span class="comment">//quotes.toscrape.com/&gt; (referer: None)</span></span><br><span class="line"><span class="number">2020</span><span class="number">-09</span><span class="number">-25</span> <span class="number">18</span>:<span class="number">09</span>:<span class="number">20</span> [scrapy.core.scraper] DEBUG: Scraped <span class="keyword">from</span> &lt;<span class="number">200</span> http:<span class="comment">//quotes.toscrape.com/&gt;</span></span><br><span class="line">&#123;<span class="string">'author'</span>: <span class="string">'Albert Einstein'</span>,</span><br><span class="line"> <span class="string">'tags'</span>: [<span class="string">'change'</span>, <span class="string">'deep-thoughts'</span>, <span class="string">'thinking'</span>, <span class="string">'world'</span>],</span><br><span class="line"> <span class="string">'text'</span>: <span class="string">'“The world as we have created it is a process of our thinking. It '</span></span><br><span class="line">         <span class="string">'cannot be changed without changing our thinking.”'</span>&#125;</span><br><span class="line"><span class="number">2020</span><span class="number">-09</span><span class="number">-25</span> <span class="number">18</span>:<span class="number">09</span>:<span class="number">20</span> [scrapy.core.scraper] DEBUG: Scraped <span class="keyword">from</span> &lt;<span class="number">200</span> http:<span class="comment">//quotes.toscrape.com/&gt;</span></span><br><span class="line">&#123;<span class="string">'author'</span>: <span class="string">'J.K. Rowling'</span>,</span><br><span class="line"> <span class="string">'tags'</span>: [<span class="string">'abilities'</span>, <span class="string">'choices'</span>],</span><br><span class="line"> <span class="string">'text'</span>: <span class="string">'“It is our choices, Harry, that show what we truly are, far more '</span></span><br><span class="line">         <span class="string">'than our abilities.”'</span>&#125;</span><br><span class="line"><span class="number">2020</span><span class="number">-09</span><span class="number">-25</span> <span class="number">18</span>:<span class="number">09</span>:<span class="number">20</span> [scrapy.core.scraper] DEBUG: Scraped <span class="keyword">from</span> &lt;<span class="number">200</span> http:<span class="comment">//quotes.toscrape.com/&gt;</span></span><br><span class="line">&#123;<span class="string">'author'</span>: <span class="string">'Albert Einstein'</span>,</span><br><span class="line"> <span class="string">'tags'</span>: [<span class="string">'inspirational'</span>, <span class="string">'life'</span>, <span class="string">'live'</span>, <span class="string">'miracle'</span>, <span class="string">'miracles'</span>],</span><br><span class="line"> <span class="string">'text'</span>: <span class="string">'“There are only two ways to live your life. One is as though nothing '</span></span><br><span class="line">         <span class="string">'is a miracle. The other is as though everything is a miracle.”'</span>&#125;</span><br><span class="line"><span class="number">2020</span><span class="number">-09</span><span class="number">-25</span> <span class="number">18</span>:<span class="number">09</span>:<span class="number">20</span> [scrapy.core.scraper] DEBUG: Scraped <span class="keyword">from</span> &lt;<span class="number">200</span> http:<span class="comment">//quotes.toscrape.com/&gt;</span></span><br><span class="line">&#123;<span class="string">'author'</span>: <span class="string">'Jane Austen'</span>,</span><br><span class="line"> <span class="string">'tags'</span>: [<span class="string">'aliteracy'</span>, <span class="string">'books'</span>, <span class="string">'classic'</span>, <span class="string">'humor'</span>],</span><br><span class="line"> <span class="string">'text'</span>: <span class="string">'“The person, be it gentleman or lady, who has not pleasure in a good '</span></span><br><span class="line">         <span class="string">'novel, must be intolerably stupid.”'</span>&#125;</span><br><span class="line"><span class="comment">/*</span></span><br><span class="line"><span class="comment">**省略部分爬取结果</span></span><br><span class="line"><span class="comment">*/</span></span><br><span class="line"><span class="number">2020</span><span class="number">-09</span><span class="number">-25</span> <span class="number">18</span>:<span class="number">09</span>:<span class="number">29</span> [scrapy.core.engine] INFO: Closing spider (finished)</span><br><span class="line"><span class="number">2020</span><span class="number">-09</span><span class="number">-25</span> <span class="number">18</span>:<span class="number">09</span>:<span class="number">29</span> [scrapy.statscollectors] INFO: Dumping Scrapy stats:</span><br><span class="line">&#123;<span class="string">'downloader/request_bytes'</span>: <span class="number">2870</span>,</span><br><span class="line"> <span class="string">'downloader/request_count'</span>: <span class="number">11</span>,</span><br><span class="line"> <span class="string">'downloader/request_method_count/GET'</span>: <span class="number">11</span>,</span><br><span class="line"> <span class="string">'downloader/response_bytes'</span>: <span class="number">24911</span>,</span><br><span class="line"> <span class="string">'downloader/response_count'</span>: <span class="number">11</span>,</span><br><span class="line"> <span class="string">'downloader/response_status_count/200'</span>: <span class="number">10</span>,</span><br><span class="line"> <span class="string">'downloader/response_status_count/404'</span>: <span class="number">1</span>,</span><br><span class="line"> <span class="string">'item_scraped_count'</span>: <span class="number">100</span>,</span><br><span class="line"> <span class="string">'memusage/max'</span>: <span class="number">49348608</span>,</span><br><span class="line"> <span class="string">'memusage/startup'</span>: <span class="number">49348608</span>,</span><br><span class="line"> <span class="string">'robotstxt/request_count'</span>: <span class="number">1</span>,</span><br><span class="line"> <span class="string">'robotstxt/response_count'</span>: <span class="number">1</span>,</span><br><span class="line"> <span class="string">'robotstxt/response_status_count/404'</span>: <span class="number">1</span>,</span><br><span class="line"> <span class="string">'scheduler/dequeued'</span>: <span class="number">10</span>,</span><br><span class="line"> <span class="string">'scheduler/dequeued/memory'</span>: <span class="number">10</span>,</span><br><span class="line"> <span class="string">'scheduler/enqueued'</span>: <span class="number">10</span>,</span><br><span class="line"> <span class="string">'scheduler/enqueued/memory'</span>: <span class="number">10</span>,</span><br><span class="line"> <span class="string">'start_time'</span>: datetime.datetime(<span class="number">2020</span>, <span class="number">9</span>, <span class="number">25</span>, <span class="number">10</span>, <span class="number">9</span>, <span class="number">18</span>, <span class="number">123168</span>)&#125;</span><br><span class="line"><span class="number">2020</span><span class="number">-09</span><span class="number">-25</span> <span class="number">18</span>:<span class="number">09</span>:<span class="number">29</span> [scrapy.core.engine] INFO: Spider closed (finished)</span><br><span class="line">➜  projects</span><br></pre></td></tr></table></figure>

<p>这里只是部分运行结果，中间一些抓取结果已省略。</p>
<p>首先，Scrapy 输出了当前的版本号以及正在启动的项目名称。接着输出了当前 settings.py 中一些重写后的配置。然后输出了当前所应用的 Middlewares 和 Pipelines。Middlewares 默认是启用的，可以在 settings.py 中修改。Pipelines 默认是空，同样也可以在 settings.py 中配置。后面会对它们进行讲解。</p>
<p>接下来就是输出各个页面的抓取结果了，可以看到爬虫一边解析，一边翻页，直至将所有内容抓取完毕，然后终止。</p>
<p>最后，Scrapy 输出了整个抓取过程的统计信息，如请求的字节数、请求次数、响应次数、完成原因等。</p>
<p>整个 Scrapy 程序成功运行。我们通过非常简单的代码就完成了一个网站内容的爬取，这样相比之前一点点写程序简洁很多。</p>
<h3 id="8-项目保存"><a href="#8-项目保存" class="headerlink" title="8.项目保存"></a>8.项目保存</h3><p>运行完 Scrapy 后，我们只在控制台看到了输出结果。如果想保存结果该怎么办呢？</p>
<p>要完成这个任务其实不需要任何额外的代码，Scrapy 提供的 Feed Exports 可以轻松将抓取结果输出。例如，我们想将上面的结果保存成 JSON 文件，可以执行如下命令：</p>
<figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl <span class="attribute">quotes</span> -o <span class="attribute">quotes</span><span class="selector-class">.json</span></span><br></pre></td></tr></table></figure>

<p>命令运行后，项目内多了一个 quotes.json 文件，文件包含了刚才抓取的所有内容，内容是 JSON 格式。</p>
<p>另外我们还可以每一个 Item 输出一行 JSON，输出后缀为 jl，为 jsonline 的缩写，命令如下所示：</p>
<figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl <span class="attribute">quotes</span> -o <span class="attribute">quotes</span><span class="selector-class">.jl</span></span><br></pre></td></tr></table></figure>

<p>或</p>
<figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl <span class="attribute">quotes</span> -o <span class="attribute">quotes</span><span class="selector-class">.jsonlines</span></span><br></pre></td></tr></table></figure>

<p>输出格式还支持很多种，例如 csv、xml、pickle、marshal 等，还支持 ftp、s3 等远程输出，另外还可以通过自定义 ItemExporter 来实现其他的输出。</p>
<p>例如，下面命令对应的输出分别为 csv、xml、pickle、marshal 格式以及 ftp 远程输出：</p>
<figure class="highlight scss"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">scrapy crawl <span class="attribute">quotes</span> -o <span class="attribute">quotes</span><span class="selector-class">.csv</span></span><br><span class="line">scrapy crawl <span class="attribute">quotes</span> -o <span class="attribute">quotes</span><span class="selector-class">.xml</span></span><br><span class="line">scrapy crawl <span class="attribute">quotes</span> -o <span class="attribute">quotes</span><span class="selector-class">.pickle</span></span><br><span class="line">scrapy crawl <span class="attribute">quotes</span> -o <span class="attribute">quotes</span><span class="selector-class">.marshal</span></span><br><span class="line">scrapy crawl <span class="attribute">quotes</span> -o ftp://user:pass@ftp.example.com/path/to/quotes.csv</span><br></pre></td></tr></table></figure>

<p>其中，ftp 输出需要正确配置用户名、密码、地址、输出路径，否则会报错。</p>
<p>通过 Scrapy 提供的 Feed Exports，我们可以轻松地输出抓取结果到文件。对于一些小型项目来说，这应该足够了。不过如果想要更复杂的输出，如输出到数据库等，我们可以使用 Item Pileline 来完成。</p>

      
    </div>
    
    
    

    
      <div>
        <div id="wechat_subscriber" style="display: block; padding: 10px 0; margin: 20px auto; width: 100%; text-align: center">
    <img id="wechat_subscriber_qcode" src="/images/wechat-qcode.jpg" alt="paragon wechat" style="width: 200px; max-width: 100%;"/>
    <div>欢迎您扫一扫上面的微信公众号，订阅我的博客！</div>
</div>

      </div>
    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Scrapy/" rel="tag"># Scrapy</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/09/22/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/" rel="next" title="操作系统学习笔记整理">
                <i class="fa fa-chevron-left"></i> 操作系统学习笔记整理
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2020/09/27/Scrapy%E5%AD%A6%E4%B9%A0%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9A%E6%A8%A1%E5%9D%97%E8%AF%A6%E8%A7%A3/" rel="prev" title="Scrapy学习（二）：模块详解">
                Scrapy学习（二）：模块详解 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  
    <div class="comments" id="comments">
    </div>
  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar.png"
                alt="paragon" />
            
              <p class="site-author-name" itemprop="name">paragon</p>
              <p class="site-description motion-element" itemprop="description">所赖君子见机，达人识命。</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/%7C%7C%20archive">
              
                  <span class="site-state-item-count">12</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">7</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/paragonxza" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:xza0226@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://twitter.com/paragon_China" target="_blank" title="Twitter">
                      
                        <i class="fa fa-fw fa-twitter"></i>Twitter</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://www.zhihu.com/people/paragonxza" target="_blank" title="知乎">
                      
                        <i class="fa fa-fw fa-vk"></i>知乎</a>
                  </span>
                
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                个人推荐
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://space.bilibili.com/384068749/" title="b站up主推荐" target="_blank">b站up主推荐</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://git-scm.com/book/zh/v2/" title="ProGit" target="_blank">ProGit</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://blog.cyasylum.top/index.php/2019/12/17/概率论与数理统计/" title="浙大概率论笔记整理" target="_blank">浙大概率论笔记整理</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#概要"><span class="nav-number">1.</span> <span class="nav-text">概要</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Scrapy框架介绍"><span class="nav-number">2.</span> <span class="nav-text">Scrapy框架介绍</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-架构模式"><span class="nav-number">2.1.</span> <span class="nav-text">1.架构模式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-数据流"><span class="nav-number">2.2.</span> <span class="nav-text">2.数据流</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-项目结构"><span class="nav-number">2.3.</span> <span class="nav-text">3.项目结构</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Scrapy入门"><span class="nav-number">3.</span> <span class="nav-text">Scrapy入门</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-项目创建"><span class="nav-number">3.1.</span> <span class="nav-text">1.项目创建</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-创建Spiders"><span class="nav-number">3.2.</span> <span class="nav-text">2.创建Spiders</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#3-创建Item"><span class="nav-number">3.3.</span> <span class="nav-text">3.创建Item</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#4-解析Response"><span class="nav-number">3.4.</span> <span class="nav-text">4.解析Response</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#5-使用Item"><span class="nav-number">3.5.</span> <span class="nav-text">5.使用Item</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#6-后续Request请求"><span class="nav-number">3.6.</span> <span class="nav-text">6.后续Request请求</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-项目运行"><span class="nav-number">3.7.</span> <span class="nav-text">7.项目运行</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-项目保存"><span class="nav-number">3.8.</span> <span class="nav-text">8.项目保存</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
            <span id="scrollpercent"><span>0</span>%</span>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2020 &mdash; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-[object Object]"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">paragon</span>

  
</div>

<!--
  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>


-->





        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      本站访客数 <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      人次
    </span>
  

  
    <span class="site-pv">
      本站总访问量 <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      次
    </span>
  
</div>








        
      </div>
    </footer>

    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  










  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item=>{
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: true,
        notify: true,
        appId: 'GGOY5y4pdXHtYiV42pSW3Eym-gzGzoHsz',
        appKey: '2jNnoktlldIOblWy8CqhAnP8',
        placeholder: '写下你想对我说的话吧...',
        avatar:'wavatar',
        guest_info:guest,
        pageSize:'10' || 10,
    });
  </script>



  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  
  

  

  

  

</body>
</html>

<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/clicklove.js"></script>

